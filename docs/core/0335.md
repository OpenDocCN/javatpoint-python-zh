# 基于 Python 的主成分分析

> 原文:[https://www . javatpoint . com/python 主成分分析](https://www.javatpoint.com/principal-component-analysis-with-python)

**主成分分析(PCA):** 是一种代数技术，用于将一组可能相关变量的观测值转换为一组线性不相关变量的值。

选择所有主成分来描述变量中的大部分可用方差，并且所有主成分彼此正交。在主成分的所有集合中，第一主成分总是具有最大方差。

## 主成分分析的不同用途:

*   主成分分析可用于发现数据中各种变量之间的相互关系。
*   主成分分析可用于解释和可视化数据集。
*   主成分分析还可以用于可视化种群之间的遗传距离和联系。
*   随着变量数量的减少，主成分分析也使分析变得简单。

主成分分析通常在正方形对称矩阵上执行，这可以是正方形和叉积矩阵或相关矩阵或协方差矩阵的纯和。如果个体差异较大，则使用相关矩阵。

## 主成分分析的目标是什么？

常设仲裁院的基本目标如下:

*   主成分分析是一种不依赖的方法，可用于将属性空间从集合的大量变量减少到更少的因子。
*   这是一种降维技术，但无法保证该维是否可解释。
*   在主成分分析中，主要工作是从一个更大的集合中选择变量的子集，这取决于哪些原始变量与本金金额具有最高的相关性。

**主轴法:**主成分分析搜索变量的线性组合，从变量中提取最大方差。一旦主成分分析完成该过程，它将前进到另一个线性组合，这将解释剩余方差的最大比率，这将导致集合的正交因子。这种方法用于分析集合变量的总方差。

**本征向量:**是矩阵相乘后保持平行的非零向量。假设‘V’是维数为 R * R 的矩阵 K 的维数为 R 的特征向量，如果 KV 和 V 平行。那么用户必须求解 KV = PV，其中 V 和 P 对于求解本征向量和特征值都是未知的。

**特征值:**在 PCA 中又称为“特征根”。这用于测量集合中所有变量的方差，由该因子报告。特征值的比例是关于变量的因素的描述重要性的比例。如果因子低，那么它对变量描述的补贴就少。

现在，我们将用 Python 讨论主成分分析。

## 以下是在 Python 中使用主成分分析的步骤:

在本教程中，我们将使用 [**wine.csv**](https://www.kaggle.com/sgus1318/winedata) 数据集。

**步骤 1:** 我们将导入库。

```py

import numpy as nmp
import matplotlib.pyplot as mpltl
import pandas as pnd

```

**第二步:**我们将导入数据集(wine.csv)

首先，我们将导入数据集，并将其分发到 X 和 Y 组件中进行数据分析。

```py

DS = pnd.read_csv('Wine.csv')

# Now, we will distribute the dataset into two components "X" and "Y"

X = DS.iloc[: , 0:13].values
Y = DS.iloc[: , 13].values

```

**第三步:**在这一步中，我们将数据集拆分为训练集和测试集。

```py

from sklearn.model_selection import train_test_split as tts

X_train, X_test, Y_train, Y_test = tts(X, Y, test_size = 0.2, random_state = 0)

```

**第 4 步:**现在，我们将进行特征缩放。

在这一步中，我们将对训练和测试集进行重新处理，例如，拟合标准尺度。

```py

from sklearn.preprocessing import StandardScaler as SS
SC = SS()

X_train = SC.fit_transform(X_train)
X_test = SC.transform(X_test)

```

**步骤 5:** 然后，应用主成分分析功能

我们将把主成分分析函数应用到训练集和测试集中进行分析。

```py

from sklearn.decomposition import PCA

PCa = PCA (n_components = 1)

X_train = PCa.fit_transform(X_train)
X_test = PCa.transform(X_test)

explained_variance = PCa.explained_variance_ratio_

```

**步骤 6:** 现在，我们将为训练集拟合逻辑回归

```py

from sklearn.linear_model import LogisticRegression as LR

classifier_1 = LR (random_state = 0)
classifier_1.fit(X_train, Y_train)

```

**输出:**

```py
LogisticRegression(random_state=0)

```

**第七步:**这里我们来预测测试集结果:

```py

Y_pred = classifier_1.predict(X_test)

```

**第八步:**我们将创建混淆矩阵。

```py

from sklearn.metrics import confusion_matrix as CM

c_m = CM (Y_test, Y_pred)

```

**步骤 9:** 然后，预测训练集的结果。

```py

from matplotlib.colors import ListedColormap as LCM

X_set, Y_set = X_train, Y_train
X_1, X_2 = nmp.meshgrid(nmp.arange(start = X_set[:, 0].min() - 1,
                     stop = X_set[: , 0].max() + 1, step = 0.01),
                     nmp.arange(start = X_set[: , 1].min() - 1,
                     stop = X_set[: , 1].max() + 1, step = 0.01))

mpltl.contourf(X_1, X_2, classifier_1.predict(nmp.array([X_1.ravel(),
             X_2.ravel()]).T).reshape(X_1.shape), alpha = 0.75,
             cmap = LCM (('yellow', 'grey', 'green')))

mpltl.xlim (X_1.min(), X_1.max())
mpltl.ylim (X_2.min(), X_2.max())

for s, t in enumerate(nmp.unique(Y_set)):
    mpltl.scatter(X_set[Y_set == t, 0], X_set[Y_set == t, 1],
                c = LCM (('red', 'green', 'blue'))(s), label = t)

mpltl.title('Logistic Regression for Training set: ')
mpltl.xlabel ('PC_1') # for X_label
mpltl.ylabel ('PC_2') # for Y_label
mpltl.legend() # for showing legend

# show scatter plot
mpltl.show()

```

**输出:**

![Principal Component Analysis (PCA) with Python](img/adb0f084a6347a3334a20dd311dba050.png)

**步骤 10:** 最后，我们将可视化测试集的结果。

```py

from matplotlib.colors import ListedColormap as LCM

X_set, Y_set = X_test, Y_test

X_1, X_2 = nmp.meshgrid(nmp.arange(start = X_set[: , 0].min() - 1,
                     stop = X_set[: , 0].max() + 1, step = 0.01),
                     nmp.arange(start = X_set[: , 1].min() - 1,
                     stop = X_set[: , 1].max() + 1, step = 0.01))

mpltl.contourf(X_1, X_2, classifier_1.predict(nmp.array([X_1.ravel(),
             X_2.ravel()]).T).reshape(X_1.shape), alpha = 0.75,
             cmap = LCM(('pink', 'grey', 'aquamarine')))

mpltl.xlim(X_1.min(), X_1.max())
mpltl.ylim(X_2.min(), X_2.max())

for s, t in enumerate(nmp.unique(Y_set)):
    mpltl.scatter(X_set[Y_set == t, 0], X_set[Y_set == t, 1],
                c = LCM(('red', 'green', 'blue'))(s), label = t)

# title for scatter plot
mpltl.title('Logistic Regression for Testing set')
mpltl.xlabel ('PC_1') # for X_label
mpltl.ylabel ('PC_2') # for Y_label
mpltl.legend()

# show scatter plot
mpltl.show()

```

**输出:**

![Principal Component Analysis (PCA) with Python](img/9df9cff947a4861eaec22d13e5858631.png)

## 结论

在本教程中，我们学习了 Python 的主成分分析、它的用途和对象，以及如何在数据集上使用它来分析数据的测试和训练集。

* * *