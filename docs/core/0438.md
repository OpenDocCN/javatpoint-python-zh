# 使用 Python 的霍夫曼编码

> 原文:[https://www.javatpoint.com/huffman-coding-using-python](https://www.javatpoint.com/huffman-coding-using-python)

**霍夫曼编码**是一种基于文本中字符的频率对文本进行压缩编码的无损方法。在信息论和计算机科学研究中，霍夫曼码是一种特殊类型的最佳前缀码，通常用于无损数据压缩。

在接下来的教程中，我们将了解霍夫曼编码的理论以及它使用 Python 编程语言的实现。但我们会谈到这一点；让我们简单了解一下霍夫曼编码。

## 理解霍夫曼编码

**霍夫曼编码**是一种无损压缩算法，用于数据压缩。这是一种由大卫·A·霍夫曼开发的算法，当时他是麻省理工学院(麻省理工学院)T4 分校的理学博士，发表在 1952 年的论文《构造最小冗余码的方法》中。这是他对计算机编程研究的一部分，通常见于编程语言，如 C、C++、Python、Java、JavaScript、Ruby 等。霍夫曼编码背后的思想过程如下:

**经常出现的字母或符号用较短的代码举例说明，不经常出现的字母或符号用较长的代码举例说明。**

这种想法导致了对需要存储更少内存的角色的有效描述。因此，我们可以得出结论，我们可以使用霍夫曼编码作为一种数据压缩方法。

现在让我们了解霍夫曼编码的理论。

## 理解霍夫曼编码理论

我们知道，一个文件作为二进制代码存储在计算机上，文件中的每个字符都被分配了一个二进制字符，对于不同的字符，字符代码通常有固定的长度。霍夫曼编码建立在文件中每个字符出现的频率和频率为零(0)的数据结构中的字符数上。典型文本文件的霍夫曼编码节省了大约 40%的实际数据大小。霍夫曼二进制代码，就像编译过的可执行代码一样，可以显著节省空间。一个二进制文件，其中一个 ASCII 字符以 0.5 的频率进行编码，其频率和分布将与其等效的 ASCII 字符有很大不同。

为了使用字符序列压缩文件，我们需要一个表，为我们提供每个字符使用的位序列。该表生成一个编码树，该编码树利用根/叶路径来创建编码字符的位序列。我们可以按照根和叶来创建一个字符列表，其中包含编码字符的最大位长和出现的次数。

我们可以使用贪婪算法来构建最优树。霍夫曼编码树返回压缩数据时使用的最小长度字符编码。树中的节点描述了字符出现的频率。根节点描述了字符串的长度，遍历树为我们提供了指定给字符的编码。一旦构建了树，遍历树就为我们提供了每个符号的相应代码。

完成后的最佳树如下表和图所示:

| **字符** | a | b | d | e | f | h | 我 | k | n | o | r | s | t | u | v |
| **频率** | nine | five | one | three | seven | three | one | one | one | four | one | five | one | Two | one | one |

![Huffman Coding using Python](../Images/b89941506f41e5db02dccb3214a2450e.png)

现在让我们在下一节中开发并实现一个利用霍夫曼编码的程序。

## 用 Python 实现霍夫曼代码

我们将首先创建一个名为**节点**的类，称为二进制霍夫曼树的节点。本质上，每个节点由一个**符号**和相关的**概率**变量、**左**和**右**子级以及**代码**变量组成。**代码**变量将是 **0** 或 **1** ，这取决于我们在通过霍夫曼树时选择的一侧(左为 0，右为 1)。

让我们考虑下面的代码片段来证明这一点:

**示例:**

```

# Node of a Huffman Tree
class Nodes:
    def __init__(self, probability, symbol, left = None, right = None):
        # probability of the symbol
        self.probability = probability

        # the symbol
        self.symbol = symbol

        # the left node
        self.left = left

        # the right node
        self.right = right

        # the tree direction (0 or 1)
        self.code = ''

```

**说明:**

在上面的代码片段中，我们将一个类定义为**节点**，并将一些参数初始化为**概率、符号、左**和右**。由于方向尚未定义，我们已初步将**左侧**和**右侧**变量的值设置为**无**。最后，我们还初始化了**代码**变量。**

 **现在，我们将添加一些支持功能。第一个功能是计算所提供数据中符号的概率。第二个功能是获得符号的编码，一旦我们有了霍夫曼树，我们将使用它。最后一个功能是获取结果(编码数据)。

**示例:**

```

""" A supporting function in order to calculate the probabilities of symbols in specified data """
def CalculateProbability(the_data):
    the_symbols = dict()
    for item in the_data:
        if the_symbols.get(item) == None:
            the_symbols[item] = 1
        else: 
            the_symbols[item] += 1     
    return the_symbols

""" A supporting function in order to print the codes of symbols by travelling a Huffman Tree """
the_codes = dict()

def CalculateCodes(node, value = ''):
    # a huffman code for current node
    newValue = value + str(node.code)

    if(node.left):
        CalculateCodes(node.left, newValue)
    if(node.right):
        CalculateCodes(node.right, newValue)

    if(not node.left and not node.right):
        the_codes[node.symbol] = newValue

    return the_codes

""" A supporting function in order to get the encoded result """
def OutputEncoded(the_data, coding):
    encodingOutput = []
    for element in the_data:
        print(coding[element], end = '')
        encodingOutput.append(coding[element])

    the_string = ''.join([str(item) for item in encodingOutput])    
    return the_string

```

**说明:**

在上面的代码片段中，我们定义了三个不同的辅助函数，以便计算给定数据中符号的概率，获得符号的编码，并获得结果。

对于第一个函数，我们将字典定义为**符号**，并使用循环的**遍历给定数据中的项目，并将它们插入字典。我们还使用了 **if-else** 条件语句来检查数据是否包含某些元素，并相应地执行操作。**

对于第二个函数，我们将另一个字典定义为**的 _codes** 。在该函数中，我们为当前节点分配了一个存储霍夫曼代码的变量，并使用 **if** 条件语句将左右节点与当前节点相加，并返回符号编码。

对于最后一个函数，我们创建了一个空数组。然后我们使用**进行**-循环遍历数据中的字符，并使用 **append()** 函数向数组中添加数据。然后，我们使用 **join()** 函数将数组中的元素连接到字符串，并返回字符串。

此外，我们还将定义另一个函数 **TotalGain** ，它接受来自 **CalculateCode** 的初始数据和字典，将符号及其代码保存在一起。该函数将帮助我们计算一位压缩和非压缩数据的大小之差。

让我们考虑下面的代码片段来证明这一点:

**示例:**

```

""" A supporting function in order to calculate the space difference between compressed and non compressed data"""    
def TotalGain(the_data, coding):
    # total bit space to store the data before compression
    beforeCompression = len(the_data) * 8
    afterCompression = 0
    the_symbols = coding.keys()
    for symbol in the_symbols:
        the_count = the_data.count(symbol)
        # calculating how many bit is required for that symbol in total
        afterCompression += the_count * len(coding[symbol])
    print("Space usage before compression (in bits):", beforeCompression)
    print("Space usage after compression (in bits):",  afterCompression)

```

**说明:**

在上面的代码片段中，我们已经定义了函数。我们计算了压缩前存储数据的总位空间。然后，我们定义了一个变量来存储数据压缩后的位空间大小，并将其赋为零。然后我们从**计算代码**函数中遍历字典中的关键字，并计算它们的出现次数。然后，我们计算了压缩后存储数据所需的位空间。

我们将使用 **HuffmanEncoding** 函数，该函数只接受数据作为参数，并使用所有上述函数返回结果编码和总增益。

让我们使用下面的代码片段来理解这一点:

**示例:**

```

def HuffmanEncoding(the_data):
    symbolWithProbs = CalculateProbability(the_data)
    the_symbols = symbolWithProbs.keys()
    the_probabilities = symbolWithProbs.values()
    print("symbols: ", the_symbols)
    print("probabilities: ", the_probabilities)

    the_nodes = []

    # converting symbols and probabilities into huffman tree nodes
    for symbol in the_symbols:
        the_nodes.append(Nodes(symbolWithProbs.get(symbol), symbol))

    while len(the_nodes) > 1:
        # sorting all the nodes in ascending order based on their probability
        the_nodes = sorted(the_nodes, key = lambda x: x.probability)
        # for node in nodes:  
        #      print(node.symbol, node.prob)

        # picking two smallest nodes
        right = the_nodes[0]
        left = the_nodes[1]

        left.code = 0
        right.code = 1

        # combining the 2 smallest nodes to create new node
        newNode = Nodes(left.probability + right.probability, left.symbol + right.symbol, left, right)

        the_nodes.remove(left)
        the_nodes.remove(right)
        the_nodes.append(newNode)

    huffmanEncoding = CalculateCodes(the_nodes[0])
    print("symbols with codes", huffmanEncoding)
    TotalGain(the_data, huffmanEncoding)
    encoded_output = OutputEncoded(the_data,huffmanEncoding)
    return encoded_output, the_nodes[0]

```

**说明:**

在上面的代码片段中，我们使用了数据参数，使用 **CalculateProbability** 函数计算符号的概率，并将结果数据存储在一个变量中。然后，我们提取了符号(键)和概率(值)，并为用户打印出来。然后我们定义了一个数组作为节点，并将符号和概率转换成霍夫曼树的节点。我们使用**进行**循环迭代符号，并将它们附加到数组中。我们还使用了**和**循环，以便根据节点的概率按升序对其进行排序。我们选择了两个最小的节点，并将它们组合起来创建一个新节点。我们从阵列中移除了最小的节点，并向其中添加了新节点。然后，我们使用**计算代码**功能来计算霍夫曼编码的代码，并为用户打印带有代码的符号。我们还使用了 **TotalGain** 函数，提供了计算压缩和非压缩数据的位空间差异所需的参数。最后，我们打印结果并返回**编码输出**和数组的第零个索引。

现在，我们将定义一个函数来解码霍夫曼编码的数据，以再次获得初始的、未压缩的数据，这是一个相当简单的过程。

让我们考虑下面的代码片段，演示解码霍夫曼编码数据的过程。

**示例:**

```

def HuffmanDecoding(encodedData, huffmanTree):
    treeHead = huffmanTree
    decodedOutput = []
    for x in encodedData:
        if x == '1':
            huffmanTree = huffmanTree.right   
        elif x == '0':
            huffmanTree = huffmanTree.left
        try:
            if huffmanTree.left.symbol == None and huffmanTree.right.symbol == None:
                pass
        except AttributeError:
            decodedOutput.append(huffmanTree.symbol)
            huffmanTree = treeHead

    string = ''.join([str(item) for item in decodedOutput])
    return string

```

**说明:**

在上面的代码片段中，我们定义了一个函数为 **HuffmanDecoding** ，它接受两个参数为 **encodedData** 和 **huffmanTree** 。然后，我们将 **huffmanTree** 变量分配给另一个变量。我们还将空数组定义为**解码输出**。然后，我们将**用于**-循环来遍历编码数据中的元素。在循环中，我们使用了 **if-elif-else** 条件语句和 **try-exception** 方法来解码编码数据并附加每个解码元素以生成解码输出。最后，我们创建了一个字符串并返回给用户。

现在，让我们初始化字符串数据并打印结果。

**示例:**

```

the_data = "AAAAAAABBCCCCCCDDDEEEEEEEEE"
print(the_data)
encoding, the_tree = HuffmanEncoding(the_data)
print("Encoded output", encoding)
print("Decoded Output", HuffmanDecoding(encoding, the_tree))

```

**说明:**

在上面的代码片段中，我们已经定义了字符串数据，并为用户打印了它。我们将这些数据传递给 **HuffmanEncoding** 函数，并将这些值存储在编码的**和编码**变量的**中。然后，我们为用户打印了编码结果。最后，我们将编码后的数据传递给 **HuffmanDecoding** 函数，并打印解码后的字符串。**

现在，让我们在项目执行之前看到它的全部内容。

完整的项目代码

让我们看看霍夫曼编码的完整 Python 项目代码。

**档案:hufffmnalgo . py**

```

# Node of a Huffman Tree
class Nodes:
    def __init__(self, probability, symbol, left = None, right = None):
        # probability of the symbol
        self.probability = probability

        # the symbol
        self.symbol = symbol

        # the left node
        self.left = left

        # the right node
        self.right = right

        # the tree direction (0 or 1)
        self.code = ''

""" A supporting function in order to calculate the probabilities of symbols in specified data """
def CalculateProbability(the_data):
    the_symbols = dict()
    for item in the_data:
        if the_symbols.get(item) == None:
            the_symbols[item] = 1
        else: 
            the_symbols[item] += 1     
    return the_symbols

""" A supporting function in order to print the codes of symbols by travelling a Huffman Tree """
the_codes = dict()

def CalculateCodes(node, value = ''):
    # a huffman code for current node
    newValue = value + str(node.code)

    if(node.left):
        CalculateCodes(node.left, newValue)
    if(node.right):
        CalculateCodes(node.right, newValue)

    if(not node.left and not node.right):
        the_codes[node.symbol] = newValue

    return the_codes

""" A supporting function in order to get the encoded result """
def OutputEncoded(the_data, coding):
    encodingOutput = []
    for element in the_data:
        # print(coding[element], end = '')
        encodingOutput.append(coding[element])

    the_string = ''.join([str(item) for item in encodingOutput])    
    return the_string

""" A supporting function in order to calculate the space difference between compressed and non compressed data"""    
def TotalGain(the_data, coding):
    # total bit space to store the data before compression
    beforeCompression = len(the_data) * 8
    afterCompression = 0
    the_symbols = coding.keys()
    for symbol in the_symbols:
        the_count = the_data.count(symbol)
        # calculating how many bit is required for that symbol in total
        afterCompression += the_count * len(coding[symbol])
    print("Space usage before compression (in bits):", beforeCompression)
    print("Space usage after compression (in bits):",  afterCompression)

def HuffmanEncoding(the_data):
    symbolWithProbs = CalculateProbability(the_data)
    the_symbols = symbolWithProbs.keys()
    the_probabilities = symbolWithProbs.values()
    print("symbols: ", the_symbols)
    print("probabilities: ", the_probabilities)

    the_nodes = []

    # converting symbols and probabilities into huffman tree nodes
    for symbol in the_symbols:
        the_nodes.append(Nodes(symbolWithProbs.get(symbol), symbol))

    while len(the_nodes) > 1:
        # sorting all the nodes in ascending order based on their probability
        the_nodes = sorted(the_nodes, key = lambda x: x.probability)
        # for node in nodes:  
        #      print(node.symbol, node.prob)

        # picking two smallest nodes
        right = the_nodes[0]
        left = the_nodes[1]

        left.code = 0
        right.code = 1

        # combining the 2 smallest nodes to create new node
        newNode = Nodes(left.probability + right.probability, left.symbol + right.symbol, left, right)

        the_nodes.remove(left)
        the_nodes.remove(right)
        the_nodes.append(newNode)

    huffmanEncoding = CalculateCodes(the_nodes[0])
    print("symbols with codes", huffmanEncoding)
    TotalGain(the_data, huffmanEncoding)
    encodedOutput = OutputEncoded(the_data,huffmanEncoding)
    return encodedOutput, the_nodes[0]

def HuffmanDecoding(encodedData, huffmanTree):
    treeHead = huffmanTree
    decodedOutput = []
    for x in encodedData:
        if x == '1':
            huffmanTree = huffmanTree.right   
        elif x == '0':
            huffmanTree = huffmanTree.left
        try:
            if huffmanTree.left.symbol == None and huffmanTree.right.symbol == None:
                pass
        except AttributeError:
            decodedOutput.append(huffmanTree.symbol)
            huffmanTree = treeHead

    string = ''.join([str(item) for item in decodedOutput])
    return string

the_data = "AAAAAAABBCCCCCCDDDEEEEEEEEE"
print(the_data)
encoding, the_tree = HuffmanEncoding(the_data)
print("Encoded output", encoding)
print("Decoded Output", HuffmanDecoding(encoding, the_tree))

```

**输出:**

```
AAAAAAABBCCCCCCDDDEEEEEEEEE
symbols:  dict_keys(['A', 'B', 'C', 'D', 'E'])
probabilities:  dict_values([7, 2, 6, 3, 9])
symbols with codes {'E': '00', 'A': '01', 'C': '10', 'D': '110', 'B': '111'}
Space usage before compression (in bits): 216
Space usage after compression (in bits): 59
Encoded output 01010101010101111111101010101010110110110000000000000000000
Decoded Output AAAAAAABBCCCCCCDDDEEEEEEEEE

```

* * ***